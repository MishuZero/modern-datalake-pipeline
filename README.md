## ğŸ—ï¸ Modern Datalake House ELT Pipeline

This project demonstrates a **modern data lakehouse architecture** built using **open-source technologies** â€” designed for scalability, version control, and analytics.

---

## ğŸ§© Architecture Overview

### ğŸ”§ Components
| Component | Role |
|------------|------|
| **Apache Airflow** | Orchestrates ETL â€” ingestion, validation, transformation |
| **MinIO (S3 Storage)** | Stores raw and processed data |
| **Apache Iceberg** | Manages structured, versioned tables in the data lake |
| **Project Nessie** | Acts as the catalog and version control for Iceberg tables |
| **Dremio** | Executes SQL queries directly on Iceberg tables |
| **Docker** | Runs all components in isolated, reproducible containers |

---


<img width="800" height="953" alt="System Design" src="https://github.com/user-attachments/assets/5c8e7571-d601-45c2-86e2-b0c697c7ac38" />

## âš™ï¸ Data Flow
1. **Ingestion** â€” Airflow pulls data from sources (DBs, APIs, CSVs).  
2. **Transformation** â€” Airflow processes and writes Iceberg tables.  
3. **Storage** â€” Data resides in MinIO (S3-compatible).  
4. **Cataloging** â€” Nessie tracks Iceberg tables, metadata, and versions.  
5. **Querying** â€” Dremio queries Iceberg tables using Nessie as the catalog.  

---

## ğŸª¶ Versioning Strategy
- **Code Version:** Managed via Git & GitHub (`git tag v1.0.0`)  
- **Data Version:** Managed by Project Nessie (`TAG v1.0.0 IN nessie`)  

---

## ğŸš€ Deployment
To start all services using Docker Compose:
```bash
docker-compose up -d

Rakibul Hasan (MishuZero)
GitHub: @MishuZero
```
